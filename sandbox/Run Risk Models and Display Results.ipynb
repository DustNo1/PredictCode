{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add open_cp code to our system path,\n",
    "#  and import tools from riskModelsGeneric\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "import riskModelsGeneric\n",
    "import crimeRiskTimeTools\n",
    "import geodataTools\n",
    "import importlib\n",
    "importlib.reload(riskModelsGeneric)\n",
    "importlib.reload(crimeRiskTimeTools)\n",
    "importlib.reload(geodataTools)\n",
    "from riskModelsGeneric import runModelExperiments\n",
    "from crimeRiskTimeTools import getSixDigitDate\n",
    "from geodataTools import list_risk_model_properties, top_geojson_features, marker_cluster_from_data\n",
    "\n",
    "print(\"Successfully imported modules.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Choose a data directory that will contain your input and output files. (Default: \"../../Data\")\n",
    "\n",
    "In that directory, you should place these files:\n",
    "- Input CSV file of crime events, with these 4 columns (the expected formats can be changed as needed via additional parameters):\n",
    "    - Time and date, currently expected as MM/DD/YYYY HH:MM:SS (AM/PM), as in 01/29/2001 03:36:25 PM\n",
    "    - Eastings, currently expected as feet instead of meters\n",
    "    - Northings, currently expected as feet instead of meters\n",
    "    - Crime type, e.g. BURGLARY\n",
    "    - (further columns will be ignored)\n",
    "- Geojson file that will generate a polygon of the relevant region\n",
    "    - For Chicago, this can be found at:\n",
    "        - https://data.cityofchicago.org/Facilities-Geographic-Boundaries/Boundaries-Community-Areas-current-/cauq-8yn6\n",
    "    - For regions of the UK, this can be made via the following process:\n",
    "        - Visit https://www.ordnancesurvey.co.uk/opendatadownload/products.html\n",
    "        - Scroll down to the \"Boundary-Line\" data, select ESRI SHAPE format, click the \"Download\" box, then scroll to the bottom and click \"Continue\".\n",
    "        - After requesting the download from the next page, wait for a download link to be sent to your email, which should allow you to download a \"force_kmls.zip\" file full of .kml files.\n",
    "        - Use the \"ogr2ogr\" tool to convert the relevant .kml file to .geojson, as in the following command: \"ogr2ogr -f GeoJSON durham.geojson durham.kml\"\n",
    "        - Convert that geojson file to a new one that has a UK-specific projection (EPSG 27700); this can be done with the function convertGeojsonUKCounty in onetimeruns.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set your parameters for the models here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some default parameters for Fantasy Durham data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following parameters are generally designed for Fantasy Durham data\n",
    "\n",
    "\n",
    "# Location of data file\n",
    "datadir = \"../../Data\"\n",
    "\n",
    "# Dataset name (to be included in names of output files)\n",
    "dataset_name = \"FantDur\"\n",
    "\n",
    "# Crime types, comma-separated as needed\n",
    "crime_type_set = \"Burglary, Vehicle crime\"\n",
    "\n",
    "# Size of grid cells\n",
    "cell_width = 500\n",
    "\n",
    "# Input csv file name\n",
    "in_csv_file_name = \"Fantasy-Durham-Data.csv\"\n",
    "\n",
    "# Geojson file\n",
    "geojson_file_name = \"Police_Force_Areas_December_2016_Durham_fixed.geojson\"\n",
    "\n",
    "# Of all planned experiments, earliest start of a TEST (not train) data set\n",
    "# Format: YYYY-MM-DD\n",
    "earliest_test_date = \"2019-09-01\"\n",
    "\n",
    "# Time between earliest experiment and latest experiment\n",
    "test_date_range = \"1W\"\n",
    "\n",
    "# Length of training data\n",
    "train_len = \"4W\"\n",
    "\n",
    "# Length of testing data\n",
    "test_len = \"1W\"\n",
    "\n",
    "# Time step offset between different experiments\n",
    "# If set to None, then test_date_step = test_len (so experiments are non-overlapping)\n",
    "test_date_step = None\n",
    "\n",
    "# Coverage rates to test, comma-separated as needed\n",
    "coverage_bounds = \"0.01,0.02,0.05,0.1\"\n",
    "\n",
    "# Maximum coverage rate to display in hit rate line graph, if generated\n",
    "# If set to None, then default is maximum from coverage_bounds\n",
    "coverage_max = \"0.1\"\n",
    "\n",
    "# Predictive models to run, comma-separated as needed\n",
    "models_to_run = \"random,naive,ideal,phs\"\n",
    "\n",
    "# Parameter list for Random model\n",
    "#  Number of different random models to generate\n",
    "num_random = 1\n",
    "\n",
    "# Parameter list for PHS model, each one comma-separated as needed\n",
    "#  Atomic unit for time bandwidths\n",
    "#  Time bandwidths\n",
    "#  Atomic unit for distance bandwidths in meters\n",
    "#  Distance bandwidths in meters\n",
    "#  Weight method (classic or linear)\n",
    "phs_time_units = \"1W\"\n",
    "phs_time_bands = \"4W, 6W\"\n",
    "phs_dist_units = \"500\"\n",
    "phs_dist_bands = \"500,1000,1500\"\n",
    "phs_weight = \"classic\"\n",
    "phs_spread = \"grid, continuous\"\n",
    "\n",
    "# CSV formatting parameters\n",
    "# If Fantasy Durham data:\n",
    "local_epsg = 27700\n",
    "csv_date_format = \"%d/%m/%Y\"\n",
    "csv_longlat = True\n",
    "csv_epsg = 27700\n",
    "csv_infeet = False\n",
    "\n",
    "# Names of the appropriate columns in the header of the CSV file\n",
    "csv_date_name       = \"Date\"       # column with date (and time)\n",
    "csv_east_name       = \"Longitude\"  # column with eastings or longitudes\n",
    "csv_north_name      = \"Latitude\"   # column with northings or latitudes\n",
    "csv_crimetypes_name = \"Crime type\" # column with type of crime\n",
    "\n",
    "csv_col_names = [csv_date_name, csv_east_name, csv_north_name, csv_crimetypes_name]\n",
    "\n",
    "print(\"Parameter assignment complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run experiments using various models and data subsets\n",
    "\n",
    "This function (runModelExperiments) takes the parameters from above and runs the models with all desired parameter combinations, using training and testing data sets over sliding-window timeframes.\n",
    "\n",
    "A csv output file will appear in the defined data directory, containing results from each model with each parameter combination on each timeframe's data set.\n",
    "\n",
    "If only 1 data timeframe is used, heatmap visualisations will be generated, appearing below as well as in the same defined data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "runModelExperiments(\n",
    "        datadir_in = datadir, \n",
    "        dataset_name_in = dataset_name, \n",
    "        crime_type_set_in = crime_type_set, \n",
    "        cell_width_in = cell_width, \n",
    "        in_csv_file_name_in = in_csv_file_name, \n",
    "        geojson_file_name_in = geojson_file_name, \n",
    "        local_epsg_in = local_epsg, \n",
    "        earliest_test_date_in = earliest_test_date, \n",
    "        test_date_range_in = test_date_range, \n",
    "        train_len_in = train_len, \n",
    "        test_len_in = test_len, \n",
    "        test_date_step_in = test_date_step, \n",
    "        coverage_bounds_in = coverage_bounds, \n",
    "        models_to_run_in = models_to_run, \n",
    "        coverage_max_in = coverage_max, \n",
    "        num_random_in = num_random, \n",
    "        phs_time_units_in = phs_time_units, \n",
    "        phs_time_bands_in = phs_time_bands, \n",
    "        phs_dist_units_in = phs_dist_units, \n",
    "        phs_dist_bands_in = phs_dist_bands, \n",
    "        phs_weight_in = phs_weight, \n",
    "        phs_spread_in = phs_spread, \n",
    "        csv_date_format = csv_date_format, \n",
    "        csv_longlat = csv_longlat, \n",
    "        csv_epsg = csv_epsg, \n",
    "        csv_infeet = csv_infeet, \n",
    "        csv_col_names = csv_col_names, \n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After conda installing Ipyleaflet we need to enable some notebook extensions and import its functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbextension enable --py --sys-prefix ipyleaflet\n",
    "from ipyleaflet import *\n",
    "print(\"Successfully imported ipyleaflet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to automatically generate the likely names of the GeoJSON output files from running the models earlier, run the following code.\n",
    "\n",
    "(Note that this makes some assumptions, namely that you're running this code on the same day that you generated the GeoJSON files.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir_standard = os.path.expandvars(os.path.expanduser(os.path.normpath(datadir)))\n",
    "date_today_str = getSixDigitDate(datetime.date.today())\n",
    "earliest_test_date_str = \"\".join(earliest_test_date.split(\"-\"))[2:]\n",
    "if test_date_step == None:\n",
    "    test_date_step = test_len\n",
    "file_name_parts = [date_today_str, \\\n",
    "                    dataset_name, \\\n",
    "                    earliest_test_date_str, \\\n",
    "                    test_date_range, \\\n",
    "                    test_date_step, \\\n",
    "                    train_len, \\\n",
    "                    test_len]\n",
    "file_name_core = \"_\".join(file_name_parts)\n",
    "\n",
    "# Name of GeoJson file with events to map\n",
    "events_geojson = os.path.join(datadir_standard, f\"train_{file_name_core}.geojson\")\n",
    "# Name of GeoJson file with risk scores for relevant cells\n",
    "results_geojson = os.path.join(datadir_standard, f\"results_{file_name_core}.geojson\")\n",
    "print(f\"Data file: {events_geojson}\")\n",
    "print(f\"Results file: {results_geojson}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can declare the full paths and names of those GeoJSON files yourself, here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of GeoJson file with events to map\n",
    "events_geojson = \"MY_DATA_DIR/MY_DATA_FILE.geojson\"\n",
    "#events_geojson = \"../../Data/train_200113_FantDur_190901_1W_1W_4W_0D.geojson\"\n",
    "\n",
    "# Name of GeoJson file with risk scores for relevant cells\n",
    "results_geojson = \"MY_DATA_DIR/MY_RESULTS_FILE.geojson\"\n",
    "#results_geojson = \"../../Data/results_200113_FantDur_190901_1W_1W_4W_0D.geojson\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data from those GeoJSON files here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(events_geojson) as eg:\n",
    "    datapoints = json.load(eg)\n",
    "with open(results_geojson) as cg:\n",
    "    cell_results = json.load(cg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This displays a list of properties from the results GeoJSON that can be selected for visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Properties available to visualize as \"property_to_map\":\\n')\n",
    "for p in list_risk_model_properties(geojson_file_contents=cell_results):\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name the property you want to examine here, along with other parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The property you want to map from the results file\n",
    "property_to_map = \"phs-6W-1500-cont-score\"\n",
    "\n",
    "# The top proportion of cells you want to highlight\n",
    "highlight_portion = 0.01\n",
    "\n",
    "# The style of highlighted cells\n",
    "highlight_cell_style = {'color':'blue',\n",
    "                        'weight':1.5,\n",
    "                        'fillColor':'transparent',\n",
    "                       }\n",
    "\n",
    "# Whether you want to plot the events from the training data\n",
    "#  Choose from:\n",
    "#   \"none\"    : Do not display the events\n",
    "#   \"point\"   : Each event is a slightly transparent black circle\n",
    "#   \"cluster\" : Multiple events cluster together as single circles,\n",
    "#                 changing at different zoom levels\n",
    "show_training_events = \"cluster\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Instantiate a map centred at Durham\n",
    "#m = Map(center=[54.776100, -1.573300], zoom=10)\n",
    "m = Map(center=[54.75, -1.573300], zoom=9)\n",
    "\n",
    "# Obtain relevant scores from GeoJSON file\n",
    "score_mapping = dict()\n",
    "for feat in cell_results['features']:\n",
    "    score_mapping[feat['id']] = feat['properties'][property_to_map]\n",
    "\n",
    "\n",
    "# Create map layer with color-coded cells reperenting risk scores\n",
    "from branca.colormap import linear\n",
    "layer = Choropleth(\n",
    "    geo_data=cell_results,\n",
    "    choro_data=score_mapping,\n",
    "    colormap=linear.YlOrRd_04,\n",
    "    border_color='transparent',\n",
    "    style={'fillOpacity': 0.8})\n",
    "m.add_layer(layer)\n",
    "\n",
    "\n",
    "# Create map layer with circles reperenting crime events\n",
    "if show_training_events != None:\n",
    "    show_training_events = show_training_events.lower()\n",
    "    if show_training_events not in [\"false\",\"no\",\"none\"]:\n",
    "        if show_training_events == \"point\":\n",
    "            with open(events_geojson) as eg:\n",
    "                datapoints = json.load(eg)\n",
    "            geojson_datapoints = GeoJSON(data=datapoints, point_style={'color': 'transparent', 'fillColor': 'black', 'radius': 5})\n",
    "            m.add_layer(geojson_datapoints)\n",
    "        elif show_training_events == \"cluster\":\n",
    "            cluster_datapoints = marker_cluster_from_data(events_geojson)\n",
    "            m.add_layer(cluster_datapoints)\n",
    "\n",
    "\n",
    "# Create map layer that highlights top-scoring cells\n",
    "top_cells_frame = top_geojson_features(results_geojson, property_to_map, highlight_portion)\n",
    "top_cells_layer = GeoData(geo_dataframe = top_cells_frame,\n",
    "                         style = highlight_cell_style)\n",
    "m.add_layer(top_cells_layer)\n",
    "\n",
    "m.add_control(FullScreenControl())\n",
    "m.add_control(LayersControl())\n",
    "\n",
    "# Display the map\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
