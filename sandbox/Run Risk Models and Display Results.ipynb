{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add open_cp code to our system path,\n",
    "#  and import tools from riskModelsGeneric\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "import riskModelsGeneric\n",
    "import crimeRiskTimeTools\n",
    "import geodataTools\n",
    "import importlib\n",
    "importlib.reload(riskModelsGeneric)\n",
    "importlib.reload(crimeRiskTimeTools)\n",
    "importlib.reload(geodataTools)\n",
    "from riskModelsGeneric import runModelExperiments\n",
    "from crimeRiskTimeTools import getSixDigitDate\n",
    "from geodataTools import list_risk_model_properties, \\\n",
    "                         top_geojson_features, \\\n",
    "                         marker_cluster_from_data, \\\n",
    "                         combine_geojson_features, \\\n",
    "                         json_dict_to_geoframe\n",
    "\n",
    "print(\"Successfully imported modules.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Choose a data directory that will contain your input and output files. (Default: \"../../Data\")\n",
    "\n",
    "In that directory, you should place these files:\n",
    "- Input CSV file of crime events, with these 4 columns (the expected formats can be changed as needed via additional parameters):\n",
    "    - Time and date, currently expected as MM/DD/YYYY HH:MM:SS (AM/PM), as in 01/29/2001 03:36:25 PM\n",
    "    - Eastings, currently expected as feet instead of meters\n",
    "    - Northings, currently expected as feet instead of meters\n",
    "    - Crime type, e.g. BURGLARY\n",
    "    - (further columns will be ignored)\n",
    "- Geojson file that will generate a polygon of the relevant region\n",
    "    - For Chicago, this can be found at:\n",
    "        - https://data.cityofchicago.org/Facilities-Geographic-Boundaries/Boundaries-Community-Areas-current-/cauq-8yn6\n",
    "    - For regions of the UK, this can be made via the following process:\n",
    "        - Visit https://www.ordnancesurvey.co.uk/opendatadownload/products.html\n",
    "        - Scroll down to the \"Boundary-Line\" data, select ESRI SHAPE format, click the \"Download\" box, then scroll to the bottom and click \"Continue\".\n",
    "        - After requesting the download from the next page, wait for a download link to be sent to your email, which should allow you to download a \"force_kmls.zip\" file full of .kml files.\n",
    "        - Use the \"ogr2ogr\" tool to convert the relevant .kml file to .geojson, as in the following command: \"ogr2ogr -f GeoJSON durham.geojson durham.kml\"\n",
    "        - Convert that geojson file to a new one that has a UK-specific projection (EPSG 27700); this can be done with the function convertGeojsonUKCounty in onetimeruns.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set your parameters for the models here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some default parameters for Fantasy Durham data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following parameters are generally designed for Fantasy Durham data\n",
    "\n",
    "\n",
    "# Location of data file\n",
    "datadir = \"../../Data\"\n",
    "\n",
    "# Dataset name (to be included in names of output files)\n",
    "dataset_name = \"FantDur\"\n",
    "\n",
    "# Crime types, comma-separated as needed\n",
    "crime_type_set = \"Burglary, Vehicle crime\"\n",
    "\n",
    "# Size of grid cells\n",
    "cell_width = 500\n",
    "\n",
    "# Input csv file name\n",
    "in_csv_file_name = \"Fantasy-Durham-Data.csv\"\n",
    "\n",
    "# Geojson file\n",
    "geojson_file_name = \"Police_Force_Areas_December_2016_Durham_fixed.geojson\"\n",
    "\n",
    "# Of all planned experiments, earliest start of a TEST (not train) data set\n",
    "# Format: YYYY-MM-DD\n",
    "earliest_test_date = \"2019-09-01\"\n",
    "\n",
    "# Time between earliest experiment and latest experiment\n",
    "test_date_range = \"1W\"\n",
    "\n",
    "# Length of training data\n",
    "train_len = \"4W\"\n",
    "\n",
    "# Length of testing data\n",
    "test_len = \"1W\"\n",
    "\n",
    "# Time step offset between different experiments\n",
    "# If set to None, then test_date_step = test_len (so experiments are non-overlapping)\n",
    "test_date_step = None\n",
    "\n",
    "# Coverage rates to test, comma-separated as needed\n",
    "coverage_bounds = \"0.01,0.02,0.05,0.1\"\n",
    "\n",
    "# Maximum coverage rate to display in hit rate line graph, if generated\n",
    "# If set to None, then default is maximum from coverage_bounds\n",
    "coverage_max = \"0.1\"\n",
    "\n",
    "# Predictive models to run, comma-separated as needed\n",
    "models_to_run = \"random,naive,ideal,phs\"\n",
    "\n",
    "# Parameter list for Random model\n",
    "#  Number of different random models to generate\n",
    "num_random = 1\n",
    "\n",
    "# Parameter list for PHS model, each one comma-separated as needed\n",
    "#  Atomic unit for time bandwidths\n",
    "#  Time bandwidths\n",
    "#  Atomic unit for distance bandwidths in meters\n",
    "#  Distance bandwidths in meters\n",
    "#  Weight method (classic or linear)\n",
    "phs_time_units = \"1W\"\n",
    "phs_time_bands = \"4W, 6W\"\n",
    "phs_dist_units = \"500\"\n",
    "phs_dist_bands = \"500,1000,1500\"\n",
    "phs_weight = \"classic\"\n",
    "phs_spread = \"continuous\"\n",
    "\n",
    "# CSV formatting parameters\n",
    "# If Fantasy Durham data:\n",
    "local_epsg = 27700\n",
    "csv_date_format = \"%d/%m/%Y\"\n",
    "csv_longlat = True\n",
    "csv_epsg = 27700\n",
    "csv_infeet = False\n",
    "\n",
    "# Names of the appropriate columns in the header of the CSV file\n",
    "csv_date_name       = \"Date\"       # column with date (and time)\n",
    "csv_east_name       = \"Longitude\"  # column with eastings or longitudes\n",
    "csv_north_name      = \"Latitude\"   # column with northings or latitudes\n",
    "csv_crimetypes_name = \"Crime type\" # column with type of crime\n",
    "\n",
    "\n",
    "# You don't need to edit anything below this line.\n",
    "# These are useful variables to pre-calculate based on the above variables,\n",
    "#  including for the interactive map section.\n",
    "csv_col_names = [csv_date_name, csv_east_name, csv_north_name, csv_crimetypes_name]\n",
    "datadir_standard = os.path.expandvars(os.path.expanduser(os.path.normpath(datadir)))\n",
    "date_today_str = getSixDigitDate(datetime.date.today())\n",
    "earliest_test_date_str = \"\".join(earliest_test_date.split(\"-\"))[2:]\n",
    "if test_date_step == None:\n",
    "    test_date_step = test_len\n",
    "file_name_core = \"_\".join([date_today_str, \\\n",
    "                            dataset_name, \\\n",
    "                            earliest_test_date_str, \\\n",
    "                            test_date_range, \\\n",
    "                            test_date_step, \\\n",
    "                            train_len, \\\n",
    "                            test_len])\n",
    "\n",
    "\n",
    "print(\"Parameter assignment complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run experiments using various models and data subsets\n",
    "\n",
    "This function (runModelExperiments) takes the parameters from above and runs the models with all desired parameter combinations, using training and testing data sets over sliding-window timeframes.\n",
    "\n",
    "A csv output file will appear in the defined data directory, containing results from each model with each parameter combination on each timeframe's data set.\n",
    "\n",
    "If only 1 data timeframe is used, heatmap visualisations will be generated, appearing below as well as in the same defined data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "runModelExperiments(\n",
    "        datadir_in = datadir, \n",
    "        dataset_name_in = dataset_name, \n",
    "        crime_type_set_in = crime_type_set, \n",
    "        cell_width_in = cell_width, \n",
    "        in_csv_file_name_in = in_csv_file_name, \n",
    "        geojson_file_name_in = geojson_file_name, \n",
    "        local_epsg_in = local_epsg, \n",
    "        earliest_test_date_in = earliest_test_date, \n",
    "        test_date_range_in = test_date_range, \n",
    "        train_len_in = train_len, \n",
    "        test_len_in = test_len, \n",
    "        test_date_step_in = test_date_step, \n",
    "        coverage_bounds_in = coverage_bounds, \n",
    "        models_to_run_in = models_to_run, \n",
    "        coverage_max_in = coverage_max, \n",
    "        num_random_in = num_random, \n",
    "        phs_time_units_in = phs_time_units, \n",
    "        phs_time_bands_in = phs_time_bands, \n",
    "        phs_dist_units_in = phs_dist_units, \n",
    "        phs_dist_bands_in = phs_dist_bands, \n",
    "        phs_weight_in = phs_weight, \n",
    "        phs_spread_in = phs_spread, \n",
    "        csv_date_format = csv_date_format, \n",
    "        csv_longlat = csv_longlat, \n",
    "        csv_epsg = csv_epsg, \n",
    "        csv_infeet = csv_infeet, \n",
    "        csv_col_names = csv_col_names, \n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After conda installing Ipyleaflet we need to enable some notebook extensions and import its functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbextension enable --py --sys-prefix ipyleaflet\n",
    "from ipyleaflet import *\n",
    "print(\"Successfully imported ipyleaflet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to automatically generate the likely names of the GeoJSON output files from running the models earlier, run the following code.\n",
    "\n",
    "(Note that this makes some assumptions, namely that you're running this code on the same day that you generated the GeoJSON files.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Name of GeoJson file with events to map\n",
    "events_geojson_file = os.path.join(datadir_standard, f\"train_{file_name_core}.geojson\")\n",
    "# Name of GeoJson file with risk scores for relevant cells\n",
    "results_geojson_file = os.path.join(datadir_standard, f\"results_{file_name_core}.geojson\")\n",
    "print(f\"Data file: {events_geojson_file}\")\n",
    "print(f\"Results file: {results_geojson_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can declare the full paths and names of those GeoJSON files yourself, here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of GeoJson file with events to map\n",
    "events_geojson_file = \"MY_DATA_DIR/MY_DATA_FILE.geojson\"\n",
    "events_geojson_file = \"../../Data/train_200115_FantDur_190901_1W_1W_4W_1W.geojson\"\n",
    "\n",
    "# Name of GeoJson file with risk scores for relevant cells\n",
    "results_geojson_file = \"MY_DATA_DIR/MY_RESULTS_FILE.geojson\"\n",
    "results_geojson_file = \"../../Data/results_200115_FantDur_190901_1W_1W_4W_1W.geojson\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data from those GeoJSON files here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(events_geojson_file) as eg:\n",
    "    datapoints = json.load(eg)\n",
    "with open(results_geojson_file) as cg:\n",
    "    cell_results = json.load(cg)\n",
    "print(\"Successfully read geojson data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This displays a list of properties from the results GeoJSON that can be selected for visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Properties available to visualize as \"property_to_map\":\\n')\n",
    "for p in list_risk_model_properties(geojson_file_contents=cell_results):\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only use this section if you want to combine properties together to make a new property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The geojson data (or, file names) with the info you want to combine.\n",
    "# If it's all from the same data, just give the file name or the data object\n",
    "# If you're pulling from multiple geojson files, make a list of them, \n",
    "#  repeating them for as many properties you're taking from them.\n",
    "# For example, if you're combining 2 properties from geojsonA and 1 property\n",
    "#  from geojsonB, this would be [geojsonA, geojsonA, geojsonB]\n",
    "\n",
    "geojson_data_to_combine = cell_results\n",
    "\n",
    "# The names of the properties you're combining.\n",
    "# If it's the same property name from all the geojsons, just name it here.\n",
    "# If you want multiple properties, make a list of them here,\n",
    "#  corresponding to the list of geojsons in geojson_data_to_combine\n",
    "\n",
    "properties_to_combine = [\"phs-4W-500-score\", \"phs-6W-1500-score\"]\n",
    "\n",
    "# The relative weights to place on each property.\n",
    "# For example, if you consider the second property to be three times as \n",
    "#  important as the first property, then use [1, 3] here.\n",
    "# That would create a new property that is equal to the sum of\n",
    "#  the first property and treble the second property.\n",
    "\n",
    "property_weights = [3,1]\n",
    "\n",
    "# The name for the new combined property you create.\n",
    "# If this is not included or set to None, then the name of the property\n",
    "#  will be the names of all the other properties, combined with \"_\"\n",
    "\n",
    "combined_property_name = \"phs-combo\"\n",
    "\n",
    "# Create the combined property here\n",
    "\n",
    "cell_results, new_property_name = combine_geojson_features(\n",
    "                                    geojson_data_list     = geojson_data_to_combine, \n",
    "                                    combine_property_list = properties_to_combine, \n",
    "                                    multiplier_list       = property_weights, \n",
    "                                    new_property_name     = combined_property_name, \n",
    "                                    )\n",
    "\n",
    "print(f\"Combined properties to make new property: {new_property_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name the property you want to view on an interactive map here, along with other parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The property you want to map from the results file\n",
    "property_to_map = \"phs-combo\"\n",
    "\n",
    "# The top proportion of cells you want to highlight\n",
    "highlight_portion = 0.01\n",
    "\n",
    "# The style of highlighted cells\n",
    "highlight_cell_style = {'color':'blue',\n",
    "                        'weight':1.5,\n",
    "                        'fillColor':'transparent',\n",
    "                       }\n",
    "\n",
    "# Whether you want to plot the events from the training data\n",
    "#  Choose from:\n",
    "#   \"none\"    : Do not display the events\n",
    "#   \"point\"   : Each event is a slightly transparent black circle\n",
    "#   \"cluster\" : Multiple events cluster together as single circles,\n",
    "#                 changing at different zoom levels\n",
    "show_training_events = \"cluster\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Instantiate a map centred at Durham\n",
    "#m = Map(center=[54.776100, -1.573300], zoom=10)\n",
    "m = Map(center=[54.75, -1.573300], zoom=9)\n",
    "\n",
    "# We now load the police force area GeoJSON file and add it as a layer to the map\n",
    "with open(os.path.join(datadir_standard, geojson_file_name), 'r') as f:\n",
    "    bounds = json.load(f)\n",
    "bounds_layer = GeoJSON(data=bounds, style = {'color': 'green', 'opacity':1, 'weight':2, 'fillColor':'transparent'})\n",
    "m.add_layer(bounds_layer)\n",
    "\n",
    "# Obtain relevant scores from GeoJSON file, and only include\n",
    "#  cells with non-zero scores\n",
    "score_mapping = dict()\n",
    "nonzero_cell_results = dict()\n",
    "for key in cell_results:\n",
    "    if key != 'features':\n",
    "        nonzero_cell_results[key] = cell_results[key]\n",
    "nonzero_cell_results['features'] = []\n",
    "for feat in cell_results['features']:\n",
    "    property_value = feat['properties'][property_to_map]\n",
    "    if property_value > 0:\n",
    "        nonzero_cell_results['features'].append(feat)\n",
    "    score_mapping[feat['id']] = property_value\n",
    "\n",
    "\n",
    "# Create map layer with color-coded cells reperenting risk scores\n",
    "from branca.colormap import linear\n",
    "layer = Choropleth(\n",
    "    geo_data=nonzero_cell_results,\n",
    "    choro_data=score_mapping,\n",
    "    colormap=linear.YlOrRd_04,\n",
    "    border_color='transparent',\n",
    "    style={'fillOpacity': 0.8})\n",
    "m.add_layer(layer)\n",
    "\n",
    "\n",
    "# Create map layer with circles representing crime events\n",
    "if show_training_events != None:\n",
    "    show_training_events = show_training_events.lower()\n",
    "    if show_training_events not in [\"false\",\"no\",\"none\"]:\n",
    "        if show_training_events == \"point\":\n",
    "            with open(events_geojson_file) as eg:\n",
    "                datapoints = json.load(eg)\n",
    "            geojson_datapoints = GeoJSON(data=datapoints, point_style={'color': 'transparent', 'fillColor': 'black', 'radius': 5})\n",
    "            m.add_layer(geojson_datapoints)\n",
    "        elif show_training_events == \"cluster\":\n",
    "            cluster_datapoints = marker_cluster_from_data(events_geojson_file)\n",
    "            m.add_layer(cluster_datapoints)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cell_results_gdf = json_dict_to_geoframe(cell_results)\n",
    "top_cells_frame = top_geojson_features(cell_results_gdf, property_to_map, highlight_portion)\n",
    "top_cells_layer = GeoData(geo_dataframe = top_cells_frame,\n",
    "                         style = highlight_cell_style)\n",
    "m.add_layer(top_cells_layer)\n",
    "\n",
    "\n",
    "\n",
    "m.add_control(FullScreenControl())\n",
    "m.add_control(LayersControl())\n",
    "\n",
    "\n",
    "print(\"Generating map...\")\n",
    "print(\"Crime types analysed: \")\n",
    "\"\"\"\n",
    "Generating Map...\n",
    "Crimes types analysed: Burglary, Vehicle Crime\n",
    "Risk identification method: PHS-4W-400m (DF note this implies that even if only one PHS model is run we should maintain the parameters in the name i.e. property_to_map can't just be PHS-Score - I guess teh alternative is pulling the individual parameter values for the method - but that will be more complex as it will be different for each method - naive etc - I'll think about this)\n",
    "Total area analysed: Analysis performed on grid of X cells of 200m x 200m = xxxxx sq km (obviously calculated from total count of cells x grid size)\n",
    "Priority boxes: x number of priority boxes selected (x% of all cells) = xxxxx sq km\n",
    "\"\"\"\n",
    "\n",
    "num_cells = len(cell_results['features'])\n",
    "sqkm_per_cell = ((cell_width*.001)**2)\n",
    "area_size = num_cells * sqkm_per_cell\n",
    "num_cells_highlight = int(num_cells * highlight_portion)\n",
    "area_highlight = num_cells_highlight * sqkm_per_cell\n",
    "date_time_now = datetime.datetime.now().strftime(\"%d/%m/%Y, %H:%M\")\n",
    "message = (\n",
    "    f\"Generating map...... {date_time_now}\\n\"\n",
    "    f\"Crime Type Analysed: {crime_type_set}\\n\" \n",
    "    f\"Risk Prediction Model: {models_to_run}\\n\"\n",
    "    f\"Mapping: {property_to_map}\\n\"\n",
    "    f\"Grid Config - Grid Size: {cell_width}m x {cell_width}m - {num_cells} grid cells analysed - Total Area: {area_size} km^2 \\n\"\n",
    "    f\"Priority Cells - Coverage {highlight_portion * 100}% - Count Cells: {num_cells_highlight} - Priority Area: {area_highlight} km^2 \\n\"\n",
    ")\n",
    "print(message)\n",
    "\n",
    "\n",
    "# Display the map\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
