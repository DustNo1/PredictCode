{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling the Data\n",
    "\n",
    "This notebook allows you to run a few models for estimating the risk of crime in grid cells over a given area (such as Durham) via a few different types of models.\n",
    "\n",
    "The following models are currently implemented:\n",
    "- Random: Rank all cells completely randomly. Baseline lowest-performing model.\n",
    "- Naive: Count the number of events per cell.\n",
    "- PHS: Each event spreads risk radially outward, decreasing in time and space depending on the parameters given to it.\n",
    "- Ideal: Impossibly ideal model that \"cheats\" by reading the testing data instead of the training data. Baseline highest-performing model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules\n",
    "\n",
    "Necessary modules are imported here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run this without editing anything\n",
    "\n",
    "# Import necessary tools from modules.\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "import riskModelsGeneric\n",
    "import crimeRiskTimeTools\n",
    "import geodataTools\n",
    "import importlib\n",
    "importlib.reload(riskModelsGeneric)\n",
    "importlib.reload(crimeRiskTimeTools)\n",
    "importlib.reload(geodataTools)\n",
    "from riskModelsGeneric import runModelExperiments, \\\n",
    "                                std_file_name\n",
    "from crimeRiskTimeTools import getSixDigitDate\n",
    "from geodataTools import list_risk_model_properties, \\\n",
    "                         top_geojson_features, \\\n",
    "                         marker_cluster_from_data, \\\n",
    "                         combine_geojson_features, \\\n",
    "                         json_dict_to_geoframe\n",
    "\n",
    "print(\"Successfully imported modules.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting Your Data\n",
    "\n",
    "Choose a data directory that will contain your input and output files. (Default: \"../../Data\")\n",
    "\n",
    "In that directory, you should place these files:\n",
    "- Input CSV file of crime events, containing somewhere within them these 4 columns (the expected formats can be changed as needed via additional parameters):\n",
    "    - Time and date\n",
    "    - East/West coordinate; could be Eastings or Longitude\n",
    "    - North/South coordinate; could be Northings or Latitude\n",
    "    - Crime type, e.g. Burglary\n",
    "    - Any other columns will be ignored.\n",
    "    - The first line of the file should be a header, with appropriate labels for these columns.\n",
    "- Geojson file that will generate a polygon of the relevant region\n",
    "    - For Chicago, this can be found at:\n",
    "        - https://data.cityofchicago.org/Facilities-Geographic-Boundaries/Boundaries-Community-Areas-current-/cauq-8yn6\n",
    "    - For regions of the UK, this can be made via the following process:\n",
    "        - Visit https://www.ordnancesurvey.co.uk/opendatadownload/products.html\n",
    "        - Scroll down to the \"Boundary-Line\" data, select ESRI SHAPE format, click the \"Download\" box, then scroll to the bottom and click \"Continue\".\n",
    "        - After requesting the download from the next page, wait for a download link to be sent to your email, which should allow you to download a \"force_kmls.zip\" file full of .kml files.\n",
    "        - Use the \"ogr2ogr\" tool to convert the relevant .kml file to .geojson, as in the following command: \"ogr2ogr -f GeoJSON durham.geojson durham.kml\"\n",
    "        - Convert that geojson file to a new one that has a UK-specific projection (EPSG 27700); this can be done with the function convertGeojsonUKCounty in onetimeruns.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters\n",
    "\n",
    "Set your parameters here. The current default arguments are for a Fantasy Durham data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Edit this, then run it\n",
    "\n",
    "\n",
    "# The following default parameters are generally designed for Fantasy Durham data\n",
    "\n",
    "# Location of data file\n",
    "datadir = \"../../Data\"\n",
    "\n",
    "# Dataset name (to be included in names of output files)\n",
    "dataset_name = \"FantDur\"\n",
    "\n",
    "# Crime types, comma-separated as needed\n",
    "#crime_type_set = \"Burglary, Vehicle crime\"\n",
    "crime_type_set = \"Burglary\"\n",
    "#crime_type_set = \"Vehicle crime\"\n",
    "\n",
    "# Size of grid cells\n",
    "cell_width = 500\n",
    "\n",
    "# Input csv file name\n",
    "in_csv_file_name = \"Fantasy-Durham-Data.csv\"\n",
    "\n",
    "# Geojson file\n",
    "area_geojson_file_name = \"Police_Force_Areas_December_2016_Durham_fixed.geojson\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Total number of experiments to run\n",
    "#  (Multiple experiments will be offset by \"time_step\", below)\n",
    "num_experiments    = 4\n",
    "# Size of the time window of events for the models to train on in each experiment\n",
    "train_len          = \"4W\"\n",
    "# Size of the subsequent time window of events for the models to be tested on in each experiment\n",
    "test_len           = \"1W\"\n",
    "# The date that marks the boundary at the end of first training window and start of \n",
    "#  the first testing window, for the first experiment\n",
    "#  (Currently, provide date in format YYYY-MM-DD)\n",
    "earliest_test_date = \"2019-09-15\"\n",
    "# Time step offset between different experiments\n",
    "# If set to None, then test_date_step = test_len (so experiments are non-overlapping)\n",
    "test_date_step     = \"1W\"\n",
    "\n",
    "\n",
    "\n",
    "# Of all planned experiments, earliest start of a TEST (not train) data set\n",
    "# Current format: YYYY-MM-DD\n",
    "#earliest_test_date = \"2019-09-01\"\n",
    "\n",
    "# Time between earliest experiment and latest experiment\n",
    "#test_date_range = \"1W\"\n",
    "\n",
    "# Length of training data\n",
    "#train_len = \"4W\"\n",
    "\n",
    "# Length of testing data\n",
    "#test_len = \"1W\"\n",
    "\n",
    "# Time step offset between different experiments\n",
    "# If set to None, then test_date_step = test_len (so experiments are non-overlapping)\n",
    "#test_date_step = None\n",
    "\n",
    "\n",
    "\n",
    "# Coverage rates to test, comma-separated as needed\n",
    "coverage_bounds = \"0.01,0.02,0.05,0.1\"\n",
    "\n",
    "# Maximum coverage rate to display in hit rate line graph, if generated\n",
    "# If set to None, then default is maximum from coverage_bounds\n",
    "coverage_max = \"0.1\"\n",
    "\n",
    "# Predictive models to run, comma-separated as needed\n",
    "models_to_run = \"random,naive,ideal,phs\"\n",
    "\n",
    "# Parameter list for PHS model, each one comma-separated as needed\n",
    "#  Atomic unit for time bandwidths\n",
    "#  Time bandwidths\n",
    "#  Atomic unit for distance bandwidths in meters\n",
    "#  Distance bandwidths in meters\n",
    "#  Weight method (classic or linear)\n",
    "phs_time_units = \"1W\"\n",
    "phs_time_bands = \"4W\"\n",
    "phs_dist_units = \"500\"\n",
    "phs_dist_bands = \"1500\"\n",
    "phs_weight = \"classic\"\n",
    "phs_spread = \"continuous\"\n",
    "\n",
    "# CSV formatting parameters\n",
    "# If Fantasy Durham data:\n",
    "local_epsg = 27700\n",
    "csv_date_format = \"%d/%m/%Y\"\n",
    "csv_longlat = True\n",
    "csv_epsg = 27700\n",
    "csv_infeet = False\n",
    "\n",
    "# Names of the appropriate columns in the header of the CSV file\n",
    "csv_date_name       = \"Date\"       # column with date (and time)\n",
    "csv_east_name       = \"Longitude\"  # column with eastings or longitudes\n",
    "csv_north_name      = \"Latitude\"   # column with northings or latitudes\n",
    "csv_crimetypes_name = \"Crime type\" # column with type of crime\n",
    "\n",
    "\n",
    "print(\"Parameter assignment complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run experiments using various models and data subsets\n",
    "\n",
    "This function (runModelExperiments) takes the parameters from above and runs the models with all desired parameter combinations, using training and testing data sets over sliding-window timeframes.\n",
    "\n",
    "A csv output file will appear in the defined data directory, containing results from each model with each parameter combination on each timeframe's data set.\n",
    "\n",
    "If only 1 data timeframe is used, heatmap visualisations will be generated, appearing below as well as in the same defined data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Run this without editing anything\n",
    "\n",
    "created_files = runModelExperiments(\n",
    "        datadir_in = datadir, \n",
    "        dataset_name_in = dataset_name, \n",
    "        crime_type_set_in = crime_type_set, \n",
    "        cell_width_in = cell_width, \n",
    "        in_csv_file_name_in = in_csv_file_name, \n",
    "        geojson_file_name_in = area_geojson_file_name, \n",
    "        local_epsg_in = local_epsg, \n",
    "        earliest_test_date_in = earliest_test_date, \n",
    "        num_experiments_in = num_experiments, \n",
    "        train_len_in = train_len, \n",
    "        test_len_in = test_len, \n",
    "        test_date_step_in = test_date_step, \n",
    "        coverage_bounds_in = coverage_bounds, \n",
    "        models_to_run_in = models_to_run, \n",
    "        coverage_max_in = coverage_max, \n",
    "        phs_time_units_in = phs_time_units, \n",
    "        phs_time_bands_in = phs_time_bands, \n",
    "        phs_dist_units_in = phs_dist_units, \n",
    "        phs_dist_bands_in = phs_dist_bands, \n",
    "        phs_weight_in = phs_weight, \n",
    "        phs_spread_in = phs_spread, \n",
    "        csv_date_format = csv_date_format, \n",
    "        csv_longlat = csv_longlat, \n",
    "        csv_epsg = csv_epsg, \n",
    "        csv_infeet = csv_infeet, \n",
    "        csv_col_names = [csv_date_name, csv_east_name, csv_north_name, csv_crimetypes_name], \n",
    "        )\n",
    "\n",
    "results_csv_file, train_geojson_file, test_geojson_file, results_geojson_file = created_files\n",
    "print(\"Output file names:\")\n",
    "for fname in created_files[:-1]:\n",
    "    print(f\" {fname}\")\n",
    "if int(num_experiments) < 2:\n",
    "    print(f\" {created_files[-1]}\")\n",
    "else:\n",
    "    results_geojson_file=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After conda installing Ipyleaflet we need to enable some notebook extensions and import its functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run this without editing anything\n",
    "\n",
    "!jupyter nbextension enable --py --sys-prefix ipyleaflet\n",
    "from ipyleaflet import *\n",
    "print(\"Successfully imported ipyleaflet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you successfully ran runModelExperiments above, performing only one experiment so that a \"results\" GeoJSON file is generated, then these file paths to the GeoJSON files will already be saved, so you don't need to run this section.\n",
    "\n",
    "However, if you want to examine a different previously created file, then you can declare the full paths of those GeoJSON files yourself, here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optional; only edit & run this if desired\n",
    "\n",
    "# Name of GeoJson file with training data's events\n",
    "train_geojson_file = \"../../Data/train_200115_FantDur_190901_1W_1W_4W_1W.geojson\"\n",
    "\n",
    "# Name of GeoJson file with testing data's events\n",
    "test_geojson_file = \"../../Data/test_200115_FantDur_190901_1W_1W_4W_1W.geojson\"\n",
    "\n",
    "# Name of GeoJson file with risk scores for relevant cells\n",
    "results_geojson_file = \"../../Data/results_200115_FantDur_190901_1W_1W_4W_1W.geojson\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data from the results GeoJSON file, and display a list of properties from the results GeoJSON that can be selected for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run this without editing\n",
    "\n",
    "with open(results_geojson_file) as cg:\n",
    "    cell_results = json.load(cg)\n",
    "print(\"Successfully read geojson data.\\n\")\n",
    "\n",
    "print('Properties available to visualize as \"property_to_map\":\\n')\n",
    "for p in list_risk_model_properties(geojson_file_contents=cell_results):\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only use this section if you want to combine properties together to make a new property, which will be saved off into a new GeoJSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optional; only edit & run this if desired\n",
    "\n",
    "# The geojson data (or, file names) with the info you want to combine.\n",
    "# If it's all from the same data, just give the file name or the data object\n",
    "# If you're pulling from multiple geojson files, make a list of them, \n",
    "#  repeating them for as many properties you're taking from them.\n",
    "# For example, if you're combining 2 properties from geojsonA and 1 property\n",
    "#  from geojsonB, this would be [geojsonA, geojsonA, geojsonB]\n",
    "\n",
    "geojson_data_to_combine = [\"../../Data/results_200123_FantDur_Burglary_190901_1W_1W_4W_1W.geojson\", \n",
    "                           \"../../Data/results_200123_FantDur_Vehiclecrime_190901_1W_1W_4W_1W.geojson\"]\n",
    "\n",
    "# The crime type analysed for each file\n",
    "crime_type_set = \"Burglary, Vehicle crime\"\n",
    "\n",
    "# The names of the properties you're combining.\n",
    "# If it's the same property name from all the geojsons, just name it here.\n",
    "# If you want multiple properties, make a list of them here,\n",
    "#  corresponding to the list of geojsons in geojson_data_to_combine\n",
    "\n",
    "properties_to_combine = \"phs-1W-6W-500-1500-score, phs-1W-6W-500-1500-score\"\n",
    "\n",
    "# The relative weights to place on each property.\n",
    "# For example, if you consider the second property to be three times as \n",
    "#  important as the first property, then use [1, 3] here.\n",
    "# That would create a new property that is equal to the sum of\n",
    "#  the first property and treble the second property.\n",
    "\n",
    "property_weights = [2,1]\n",
    "\n",
    "# The name for the new combined property you create.\n",
    "# If this is not included or set to None, then the name of the property\n",
    "#  will be the names of all the other properties, combined with \"_\"\n",
    "\n",
    "combined_property_name = \"phs-combo\"\n",
    "\n",
    "# The combined property is created here\n",
    "\n",
    "cell_results, new_property_name, new_geojson_file = combine_geojson_features(\n",
    "                        geojson_data_list     = geojson_data_to_combine, \n",
    "                        combine_property_list = properties_to_combine, \n",
    "                        multiplier_list       = property_weights, \n",
    "                        new_property_name     = combined_property_name, \n",
    "                        )\n",
    "\n",
    "print(f\"Combined properties to make new property: {new_property_name}\")\n",
    "print(f\"New GeoJSON file saved at: {new_geojson_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name the property you want to view on an interactive map here, along with other parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Edit this, then run it\n",
    "\n",
    "# The property you want to map from the results file\n",
    "property_to_map = \"phs-combo\"\n",
    "\n",
    "# The top proportion of cells you want to highlight\n",
    "highlight_portion = 0.01\n",
    "\n",
    "# The style of highlighted cells\n",
    "highlight_cell_style = {'color':'blue',\n",
    "                        'weight':1.5,\n",
    "                        'fillColor':'transparent',\n",
    "                       }\n",
    "\n",
    "# Whether you want to plot the events from the training data\n",
    "#  Choose from:\n",
    "#   \"none\"    : Do not display the events\n",
    "#   \"point\"   : Each event is a slightly transparent black circle\n",
    "#   \"cluster\" : Multiple events cluster together as single circles,\n",
    "#                 changing at different zoom levels\n",
    "show_training_events = \"none\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Run this without editing anything\n",
    "\n",
    "# Instantiate a map centred at Durham\n",
    "#m = Map(center=[54.776100, -1.573300], zoom=10)\n",
    "m = Map(center=[54.75, -1.573300], zoom=9)\n",
    "\n",
    "# We now load the police force area GeoJSON file and add it as a layer to the map\n",
    "with open(std_file_name([datadir, area_geojson_file_name]), 'r') as f:\n",
    "    bounds = json.load(f)\n",
    "bounds_layer = GeoJSON(data=bounds, style = {'color': 'green', 'opacity':1, 'weight':2, 'fillColor':'transparent'})\n",
    "m.add_layer(bounds_layer)\n",
    "\n",
    "# Obtain relevant scores from GeoJSON file, and only include\n",
    "#  cells with non-zero scores\n",
    "score_mapping = dict()\n",
    "nonzero_cell_results = dict()\n",
    "for key in cell_results:\n",
    "    if key != 'features':\n",
    "        nonzero_cell_results[key] = cell_results[key]\n",
    "nonzero_cell_results['features'] = []\n",
    "for feat in cell_results['features']:\n",
    "    property_value = feat['properties'][property_to_map]\n",
    "    if property_value > 0:\n",
    "        nonzero_cell_results['features'].append(feat)\n",
    "    score_mapping[feat['id']] = property_value\n",
    "\n",
    "\n",
    "# Create map layer with color-coded cells reperenting risk scores\n",
    "from branca.colormap import linear\n",
    "layer = Choropleth(\n",
    "    geo_data=nonzero_cell_results,\n",
    "    choro_data=score_mapping,\n",
    "    colormap=linear.YlOrRd_04,\n",
    "    border_color='transparent',\n",
    "    style={'fillOpacity': 0.8})\n",
    "m.add_layer(layer)\n",
    "\n",
    "\n",
    "# Create map layer with circles representing crime events\n",
    "if show_training_events != None:\n",
    "    show_training_events = show_training_events.lower()\n",
    "    if show_training_events not in [\"false\",\"no\",\"none\"]:\n",
    "        if show_training_events == \"point\":\n",
    "            with open(train_geojson_file) as eg:\n",
    "                datapoints = json.load(eg)\n",
    "            geojson_datapoints = GeoJSON(data=datapoints, point_style={'color': 'transparent', 'fillColor': 'black', 'radius': 5})\n",
    "            m.add_layer(geojson_datapoints)\n",
    "        elif show_training_events == \"cluster\":\n",
    "            cluster_datapoints = marker_cluster_from_data(train_geojson_file)\n",
    "            m.add_layer(cluster_datapoints)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cell_results_gdf = json_dict_to_geoframe(cell_results)\n",
    "top_cells_frame = top_geojson_features(cell_results_gdf, property_to_map, highlight_portion)\n",
    "top_cells_layer = GeoData(geo_dataframe = top_cells_frame,\n",
    "                         style = highlight_cell_style)\n",
    "m.add_layer(top_cells_layer)\n",
    "\n",
    "\n",
    "\n",
    "m.add_control(FullScreenControl())\n",
    "m.add_control(LayersControl())\n",
    "\n",
    "\n",
    "num_cells = len(cell_results['features'])\n",
    "sqkm_per_cell = ((cell_width*.001)**2)\n",
    "area_size = num_cells * sqkm_per_cell\n",
    "num_cells_highlight = int(num_cells * highlight_portion)\n",
    "area_highlight = num_cells_highlight * sqkm_per_cell\n",
    "date_time_now = datetime.datetime.now().strftime(\"%d/%m/%Y, %H:%M\")\n",
    "message = (\n",
    "    f\"Generating map...... {date_time_now}\\n\", \n",
    "    f\"Crime Type Analysed: {crime_type_set}\\n\", \n",
    "    f\"Mapping: {property_to_map}\\n\", \n",
    "    f\"Grid Config - Grid Size: {cell_width}m x {cell_width}m - \"+\\\n",
    "                    f\"{num_cells} grid cells analysed - \"+\\\n",
    "                    f\"Total Area: {area_size:.2f} km^2 \\n\", \n",
    "    f\"Priority Cells - Coverage {highlight_portion * 100}% - \"+\\\n",
    "                    f\"Count Cells: {num_cells_highlight} - \"+\\\n",
    "                    f\"Priority Area: {area_highlight:.2f} km^2 \\n\", \n",
    ")\n",
    "print(*message)\n",
    "\n",
    "\n",
    "# Display the map\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
